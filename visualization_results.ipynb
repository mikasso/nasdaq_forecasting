{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\repos\\nasdaq_forecasting\\.venv\\lib\\site-packages\\shap\\utils\\_clustering.py:35: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  def _pt_shuffle_rec(i, indexes, index_mask, partition_tree, M, pos):\n",
      "c:\\repos\\nasdaq_forecasting\\.venv\\lib\\site-packages\\shap\\utils\\_clustering.py:54: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  def delta_minimization_order(all_masks, max_swap_size=100, num_passes=2):\n",
      "c:\\repos\\nasdaq_forecasting\\.venv\\lib\\site-packages\\shap\\utils\\_clustering.py:63: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  def _reverse_window(order, start, length):\n",
      "c:\\repos\\nasdaq_forecasting\\.venv\\lib\\site-packages\\shap\\utils\\_clustering.py:69: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  def _reverse_window_score_gain(masks, order, start, length):\n",
      "c:\\repos\\nasdaq_forecasting\\.venv\\lib\\site-packages\\shap\\utils\\_clustering.py:77: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  def _mask_delta_score(m1, m2):\n",
      "c:\\repos\\nasdaq_forecasting\\.venv\\lib\\site-packages\\shap\\links.py:5: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  def identity(x):\n",
      "c:\\repos\\nasdaq_forecasting\\.venv\\lib\\site-packages\\shap\\links.py:10: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  def _identity_inverse(x):\n",
      "c:\\repos\\nasdaq_forecasting\\.venv\\lib\\site-packages\\shap\\links.py:15: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  def logit(x):\n",
      "c:\\repos\\nasdaq_forecasting\\.venv\\lib\\site-packages\\shap\\links.py:20: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  def _logit_inverse(x):\n",
      "c:\\repos\\nasdaq_forecasting\\.venv\\lib\\site-packages\\shap\\utils\\_masked_model.py:363: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  def _build_fixed_single_output(averaged_outs, last_outs, outputs, batch_positions, varying_rows, num_varying_rows, link, linearizing_weights):\n",
      "c:\\repos\\nasdaq_forecasting\\.venv\\lib\\site-packages\\shap\\utils\\_masked_model.py:385: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  def _build_fixed_multi_output(averaged_outs, last_outs, outputs, batch_positions, varying_rows, num_varying_rows, link, linearizing_weights):\n",
      "c:\\repos\\nasdaq_forecasting\\.venv\\lib\\site-packages\\shap\\utils\\_masked_model.py:428: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  def _init_masks(cluster_matrix, M, indices_row_pos, indptr):\n",
      "c:\\repos\\nasdaq_forecasting\\.venv\\lib\\site-packages\\shap\\utils\\_masked_model.py:439: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  def _rec_fill_masks(cluster_matrix, indices_row_pos, indptr, indices, M, ind):\n",
      "c:\\repos\\nasdaq_forecasting\\.venv\\lib\\site-packages\\shap\\maskers\\_tabular.py:186: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  def _single_delta_mask(dind, masked_inputs, last_mask, data, x, noop_code):\n",
      "c:\\repos\\nasdaq_forecasting\\.venv\\lib\\site-packages\\shap\\maskers\\_tabular.py:197: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  def _delta_masking(masks, x, curr_delta_inds, varying_rows_out,\n",
      "c:\\repos\\nasdaq_forecasting\\.venv\\lib\\site-packages\\shap\\maskers\\_image.py:175: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  def _jit_build_partition_tree(xmin, xmax, ymin, ymax, zmin, zmax, total_ywidth, total_zwidth, M, clustering, q):\n",
      "c:\\repos\\nasdaq_forecasting\\.venv\\lib\\site-packages\\shap\\explainers\\_partition.py:676: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  def lower_credit(i, value, M, values, clustering):\n",
      "\u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "\u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "INFO:Dataset:Loading dataset from data/preprocessed/datasets_hourly.pkl\n"
     ]
    }
   ],
   "source": [
    "import const as CONST\n",
    "import matplotlib.pyplot as plt\n",
    "from darts.metrics import mape\n",
    "from darts import TimeSeries\n",
    "import pandas as pd\n",
    "import const as CONST\n",
    "import warnings\n",
    "import os\n",
    "from model_configs import MODEL_CONFIGS \n",
    "plt.style.use('ggplot')\n",
    "import matplotlib\n",
    "matplotlib.rcParams['figure.figsize'] = (20, 10)\n",
    "warnings.simplefilter(action=\"ignore\", category=FutureWarning)\n",
    "import darts\n",
    "\n",
    "from view_results import load_results\n",
    "from darts.datasets import AirPassengersDataset\n",
    "from darts.explainability.tft_explainer import TFTExplainer\n",
    "from darts.models.forecasting.torch_forecasting_model import TorchForecastingModel\n",
    "from datasets import SeqDataset, Datasets, DatasetAccesor, DatasetTransformer, load_datasets\n",
    "from model_configs import ModelConfig, ModelTypes\n",
    "from darts.models import TFTModel\n",
    "import numpy as np \n",
    "ds = load_datasets()\n",
    "from darts import concatenate\n",
    "from datasets import load_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<contextlib.ExitStack at 0x245faf77a00>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "plt.ioff()\n",
    "loss_dict = {}\n",
    "for config in MODEL_CONFIGS:\n",
    "    figure = joblib.load(f\"{config.result_path}/loss.pkl\")\n",
    "    axes = figure.get_axes()[0]\n",
    "    train = axes.get_lines()[0].get_ydata()\n",
    "    val = axes.get_lines()[1].get_ydata()\n",
    "    loss_dict[f\"{config.model_type.value} h={config.output_len}\"] = (train, val)\n",
    "plt.ioff()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "plt.close()\n",
    "plt.ion()\n",
    "figure, axis = plt.subplots(6, 3)\n",
    "figure.tight_layout(pad=2.0)\n",
    "figure.set_figheight(20)\n",
    "\n",
    "min_val_losses = pd.DataFrame(index=[\"h=1\",'h=8','h=40'], columns=[\"RNN\",\"LSTM\",\"GRU\",\"TCN\",\"Transformer\",\"TFT\"])\n",
    "\n",
    "for idx, (key, value) in enumerate(loss_dict.items()):\n",
    "        ax = axis[idx // 3, idx % 3]\n",
    "        ax.plot(value[0])\n",
    "        ax.plot(value[1])\n",
    "        k = key.split(\" \")\n",
    "        min_val_losses[k[0]][k[1]] = min(value[1])\n",
    "        ax.set_yticks(np.arange(0, 0.005, 0.001))\n",
    "        ax.set_ylim(0, 0.005)\n",
    "        ax.set_title(key)\n",
    "\n",
    "labels = [\"Zbiór uczący\", \"Zbiór walidacyjny\"]\n",
    "figure.legend(labels, loc='lower right',  ncol=len(labels),  prop={'size': 16}, bbox_transform=figure.transFigure)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:darts.models.forecasting.torch_forecasting_model:loading best-epoch=22-val_loss=0.00.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "GPU available but not used. Set `accelerator` and `devices` using `Trainer(accelerator='gpu', devices=1)`.\n",
      "The dataloader, predict_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 12 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa61d5c42b894c709c3147928ecdc6bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:darts.models.forecasting.torch_forecasting_model:loading best-epoch=19-val_loss=0.00.ckpt\n",
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "GPU available but not used. Set `accelerator` and `devices` using `Trainer(accelerator='gpu', devices=1)`.\n",
      "The dataloader, predict_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 12 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "292295b45132436e90e3dfb9af966d40",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:darts.models.forecasting.torch_forecasting_model:loading best-epoch=22-val_loss=0.00.ckpt\n",
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "GPU available but not used. Set `accelerator` and `devices` using `Trainer(accelerator='gpu', devices=1)`.\n",
      "The dataloader, predict_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 12 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60197c845a144597a3cf09b5ab39bc21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from validate import load_model\n",
    "\n",
    "encoder_importances = []\n",
    "statics_importances = []\n",
    "for model_name in [\"ModelTypes.tft_out_1\",\"ModelTypes.tft_out_8\",\"ModelTypes.tft_out_40\"]:\n",
    "    model = load_model(model_name=model_name,  map_location=\"cpu\")\n",
    "    model.to_cpu()\n",
    "    # create the explainer and generate explanations\n",
    "    explainer = TFTExplainer(model, ds.transformed.train, ds.covariates.train)\n",
    "    results = explainer.explain()\n",
    "    encoder_importances.append(pd.concat(results.get_encoder_importance()))\n",
    "    statics_importances.append(pd.concat(results.get_static_covariates_importance()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gold_pastcov</th>\n",
       "      <th>shares_pastcov</th>\n",
       "      <th>hour_pastcov</th>\n",
       "      <th>price_target</th>\n",
       "      <th>Miesiąc</th>\n",
       "      <th>Dzień tygodnia</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>h=1</th>\n",
       "      <td>0.914286</td>\n",
       "      <td>5.500000</td>\n",
       "      <td>8.757144</td>\n",
       "      <td>33.614285</td>\n",
       "      <td>8.185715</td>\n",
       "      <td>9.485714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>h=8</th>\n",
       "      <td>4.528571</td>\n",
       "      <td>9.442857</td>\n",
       "      <td>2.142857</td>\n",
       "      <td>67.385719</td>\n",
       "      <td>5.021429</td>\n",
       "      <td>2.157143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>h=40</th>\n",
       "      <td>11.228571</td>\n",
       "      <td>7.700000</td>\n",
       "      <td>7.014286</td>\n",
       "      <td>29.514284</td>\n",
       "      <td>8.392858</td>\n",
       "      <td>7.978572</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      gold_pastcov  shares_pastcov  hour_pastcov  price_target   Miesiąc   \n",
       "h=1       0.914286        5.500000      8.757144     33.614285  8.185715  \\\n",
       "h=8       4.528571        9.442857      2.142857     67.385719  5.021429   \n",
       "h=40     11.228571        7.700000      7.014286     29.514284  8.392858   \n",
       "\n",
       "      Dzień tygodnia  \n",
       "h=1         9.485714  \n",
       "h=8         2.157143  \n",
       "h=40        7.978572  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame([x.mean() for x in  encoder_importances], index=[\"h=1\",\"h=8\",\"h=40\"])\n",
    "month = (df[\"month_sin_pastcov\"] + df[\"month_cos_pastcov\"]) / 2\n",
    "weekday = (df[\"weekday_sin_pastcov\"] + df[\"weekday_cos_pastcov\"]) / 2\n",
    "df = df.drop(columns=[\"month_cos_pastcov\",\t\"weekday_cos_pastcov\",\t\"month_sin_pastcov\",\t\"weekday_sin_pastcov\",\t\"add_relative_index_futcov\"\t])\n",
    "df[\"Miesiąc\"] = month\n",
    "df[\"Dzień tygodnia\"] = weekday\n",
    "df.to_csv(CONST.PATHS.RESULTS+\"/general/tft_weights.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_end_value = None\n",
    "real_values = None\n",
    "UP = True\n",
    "DOWN = False\n",
    "\n",
    "def key(config):\n",
    "    return f\"{config.model_type.value} {config.output_len}\"\n",
    "\n",
    "df = pd.DataFrame(index=[key(x)  for x  in MODEL_CONFIGS], columns=CONST.TICKERS)\n",
    "\n",
    "for config in MODEL_CONFIGS:\n",
    "    predictions = load_results(config)\n",
    "    for idx, series_predictions in enumerate(predictions):\n",
    "        original_series = ds.original.series[idx]\n",
    "        trend = []\n",
    "        predicted_trend = []\n",
    "        for prediction in series_predictions:\n",
    "            init_value_index = original_series.get_index_at_point(prediction.start_time()) - 1\n",
    "            init_value_timestamp = original_series.get_timestamp_at_point(init_value_index)\n",
    "            original_init_value = original_series[init_value_timestamp].first_value()\n",
    "            original_end_value = original_series[prediction.end_time()].first_value()\n",
    "            predicted_end_value = prediction[prediction.end_time()].first_value()\n",
    "            trend.append(original_init_value < original_end_value)\n",
    "            predicted_trend.append(original_init_value < predicted_end_value)\n",
    "        acc = np.sum(np.array(trend) == np.array(predicted_trend))/ len(trend)\n",
    "        df[CONST.TICKERS[idx]][key(config)] = acc\n",
    "        \n",
    "df.to_csv(CONST.PATHS.RESULTS+\"/general/accuracy.csv\")\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
